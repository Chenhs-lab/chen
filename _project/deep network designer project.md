---
layout: course_layout
title: "deep network designer project"
---
# 臺北市私立薇閣高級中學114學年度第1學期工程專題
班級     二辛        	座號      40        	姓名    	陳泓碩
## 一、主題：
比較卷積神經網路，利用matlab深度學習(deep network designer)做寵物的分類，比較SqueezeNet與GoogLeNet的差異   
兩者皆是卷積神經網絡（CNN）發展史上的重要模型，但它們的設計初衷與應用場合卻有顯著差異

| SqueezeNet | 2016 年由UC Berkeley, Stanford發布，目標是以 50 倍小的參數達到 AlexNet 的準確率，約 4.8 MB，經 Deep Compression 技術壓縮甚至可小於 0.5 MB（僅 120 萬個參數），對硬體友好度極高，使用1&times;1卷積是為了取代。儘可能將3&times;3卷積替換成1&times;1，直接從源頭減少參數數量 | 
| :--- | :--- | 
| GoogLeNet | 2014 年由Google發布(又稱Inception-v1)，提高精度同時控制計算複雜度(超越AlexNet)，約 28 MB（700 萬個參數），所以對硬體友好度就沒這麼高，使用1×1卷積主要是為了降維。在進行大尺寸卷積之前先減少通道數，防止計算量過大 |
## 二、收集資料：
### （包含資料篩選、資料預處理、格式轉換）
我選擇以寵物的分類作為主題，先在網路上收集資料後，利用Xnview全選進行批次轉換，轉成可用的jpg檔再進行重新命名



## 三、建立模型挖掘資料：
### （使用資料探勘或機器學習方法、訓練資料比率、使用參數…等）
本次試驗我各分類都選了60張照片，其中70%為訓練用，30%為測試用，所以各分組皆有42張訓練圖片
<img width="761" height="378" alt="image" src="https://github.com/user-attachments/assets/d2a934bc-b039-4ce3-9382-046f3a836e52" /></br>









## 四、實驗結果
### （程式碼（含註解）、實驗結果）
### 1.squeezeNet

 第一次做出來只有70.83%推測可能是因為最後一項分類包含太多種動物，導致訓練率不足80%，所以我將第四個分類從4種動物改為只有兔子，希望能將訓練率提高。如下圖，訓練出的模型將貓判斷錯誤


 ### 2.googLeNet
 第二個我選擇的神經網路是google Net 希望透過兩個不同的卷積神經網路所做出來的結果進行比較，
我會選擇GoogLeNet是因為它看起來較SqueezeNet複雜




## 五、實驗結果討論
### （從實驗的結果觀察到的情況）
根據多次試驗的結果發現即使訓練量、方法、參數......等皆相同，每次所訓練出來的成果也會存在些微差異，以及以上兩次分別為SqueezeNet與GoogLeNet的訓練成果可以看出SqueezeNet的訓練率不如GoogLeNet來的高，雖然就寵物分類這種特徵明顯的判斷而言，兩者的準確率都能輕鬆達到90%以上，但如果要判斷其他更相近、特徵較不明顯的物種，兩者就可能產生較大的區別

在上面這張倉鼠的圖片中，可以發現SqueezeNet的準確率反而比GoogLeNet高上不少，明明兩者在訓練率上有一定落差，為什麼會造成這種結果呢?首先要先從兩者的差別開始說起，GoogLeNet旨在實現高分類準確率的同時提高計算效率，模型大小相對較小，在保持與 AlexNet 相當準確率的前提下，最大程度縮小模型大小 (<1MB)，可謂是極小，可以比 AlexNet 小 50 倍。再來，兩者相比之下的優點也十分明顯，SqueezeNet的訓練參數和延遲都比GoogLeNet來的小很多，這就使訓練過程中其速度有顯著差別，雖然GoogLeNet也稱得上是高效的模型，但相比之下，還是SqueezeNet快很多，而GoogLeNet則是在準確率上有較大優勢，在上方的訓練率差距就能明顯看出，經過上網收集資料後，得出應該是由於一種名為
“過度擬合”的現象導致。這是一種不理想的機器學習行為，會導致不準確的結果，會發生這種問題的原因也很簡單，訓練資料量的不足、或者是由於訓練模型太複雜，因此也學習了資料中的雜訊、再來可能是訓練時長太長導致系統學習了資料中的雜訊，GoogLeNet相較SqueezeNet複雜了不少，再加上SqueezeNet又大幅縮短訓練時間，所以在這種訓練量少的情況下反而能有更高準確率，總結來說，神經網路會因為性質不同而導致我們在不同情況下訓練時要選擇不同的神經網路。

## 六、心得感想
這次期末報告利用Matlab的Deep Network Designer進行的期末報告結合了本學習工程設計的兩大課程主題，Matlab與人工智慧，最初選擇做寵物分類是覺得在資料量少的情況下，特徵相對較明顯的動物應該能讓訓練率提升，選擇SqueezeNet與GoogLeNet則是想對兩種不同取向的神經網路進行對比，原本我以為模型複雜、參數較多的GoogLeNet會有更高的準確率，一開始從訓練率來看確實比SqueezeNet高了10幾%，不過當兩者分別訓練出來的模型將圖片輸入後發現有些圖片跑出來的準確率卻是SqueezeNet比GoogLeNet高了不少，最初我會想用更多不同圖片來測試是我看到兔子的測試結果SqueezeNet的99.9%對比GoogLeNet的92.2%再加上蒐集資料的時候本來就在四種動物都各多留了幾張以備不時之需，上圖的倉鼠照片便是測試下來差距較為明顯的，於是在發現這個問題後經過資料查詢，學到了”過度擬合”這個觀念，算是預期外的收穫。透過這次利用SqueezeNet和GoogLeNet兩個卷積神經網路的實作讓我對於機器學習有了更深入的了解

## 七、參考資料 
https://aws.amazon.com/tw/what-is/overfitting/
https://www.matlabsolutions.com/documentation/deeplearning/transfer-learning-with-deep-network-designer.php
